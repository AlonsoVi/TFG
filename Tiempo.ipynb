{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytesseract import Output\n",
    "import re\n",
    "import cv2 #opencv-python-headless             4.5.4.58/ ahora opencv-python                      4.5.5.62\n",
    "import pytesseract\n",
    "#import easyocr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import rv_histogram\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'D:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "custom_config = r'--oem 3 --psm 1 -l spa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.GaussianBlur(image, (7, 7), 0)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(img):\n",
    "    ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return th2\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 2)#1\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 3)#3\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#C\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#Rotación\n",
    "def getSkewAngle(cvImage):\n",
    "    newImage = cvImage.copy()\n",
    "    gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Apply dilate to merge text into meaningful lines/paragraphs.\n",
    "    # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.\n",
    "    # But use smaller kernel on Y axis to separate between different blocks of text\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=5)\n",
    "\n",
    "    # Find all contours\n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "    # Find largest contour and surround in min area box\n",
    "    largestContour = contours[0]\n",
    "    minAreaRect = cv2.minAreaRect(largestContour)\n",
    "\n",
    "    # Determine the angle. Convert it to the value that was originally used to obtain skewed image\n",
    "    angle = minAreaRect[-1]\n",
    "    if angle < -45:\n",
    "        angle = 90. + angle\n",
    "    print(angle)\n",
    "    return -1 * angle + 90\n",
    "# Rotar alrededor del centro\n",
    "def rotateImage(cvImage, angle):\n",
    "    newImage = cvImage.copy()\n",
    "    (h, w) = newImage.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return newImage\n",
    "\n",
    "# Juntar\n",
    "def deskew(cvImage):\n",
    "    angle = getSkewAngle(cvImage)\n",
    "    return rotateImage(cvImage, -1.0 * angle)\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "#Returns text in image\n",
    "def imagetotext(imagepath): #imagepath=str\n",
    "    img = cv2.imread(imagepath)\n",
    "    text = pytesseract.image_to_string(img, config=custom_config)\n",
    "    return text\n",
    "    \n",
    "def takepicture():\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    check, frame = webcam.read()\n",
    "    cv2.imwrite(filename=r'saved_img.jpg', img=frame)\n",
    "    webcam.release()\n",
    "\n",
    "def tts(text):\n",
    "    engine.say(text);\n",
    "    engine.runAndWait()\n",
    "\n",
    "def remove_newlines(text):\n",
    "        return text.replace(\"\\n\",\" \") #para quitar las nuevas líneas y que lea con más fluidez\n",
    "    \n",
    "def leertxt(archivotxt):\n",
    "    content = open(archivotxt, \"r\", encoding='utf-8').read()\n",
    "    lecturatxt = re.split('\\s|\\n',content)\n",
    "    try:\n",
    "        while True:\n",
    "            lecturatxt.remove('')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return lecturatxt\n",
    "\n",
    "def listafiltrada(archivoimagen):\n",
    "    img = cv2.imread(archivoimagen)\n",
    "    text = pytesseract.image_to_data(img, config=custom_config, output_type=Output.DATAFRAME).dropna()\n",
    "    #text['text'] = text['text'].lower()\n",
    "    lista = text[\"text\"].tolist()\n",
    "    try:\n",
    "        while True:\n",
    "            lista.remove('')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        while True:\n",
    "            lista.remove(' ')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        while True:\n",
    "            lista.remove('  ')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if lista[-1].isnumeric() == True:\n",
    "        lista.pop(-1)\n",
    "    filterlist = []\n",
    "    skip = []\n",
    "    for i in range(len(lista)): #para juntar última palabra de línea con siguiente\n",
    "        if i in skip:\n",
    "            continue\n",
    "        if lista[i].find(\"-\")!=-1:\n",
    "            if i+1>=len(lista): #por si es la última palabra de la lista\n",
    "                break\n",
    "            else:\n",
    "                filterlist.append(lista[i].replace('-', '')+lista[i+1]) \n",
    "                skip.append(i+1)\n",
    "        else:\n",
    "            filterlist.append(lista[i])\n",
    "    try:\n",
    "        while True:\n",
    "            filterlist.remove('')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        while True:\n",
    "            filterlist.remove(' ')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        while True:\n",
    "            filterlist.remove('  ')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return filterlist\n",
    "\n",
    "def accuracyAlonso(lista1,lista2):\n",
    "    p = 0\n",
    "    j = 0\n",
    "    skip = []\n",
    "    minimo = min([len(lista1),len(lista2)])\n",
    "    i = 0\n",
    "    while i < minimo:\n",
    "        if i in skip:\n",
    "            break\n",
    "        if lista1[i]==lista2[i]:\n",
    "            p += 1\n",
    "        elif lista1[i]==lista2[i+1]:\n",
    "            p += 1\n",
    "            lista2.pop(i)\n",
    "            j += 1\n",
    "            skip.append(minimo-j-1)\n",
    "        elif lista1[i+1]==lista2[i]:\n",
    "            p += 1\n",
    "            lista1.pop(i)\n",
    "            j += 1\n",
    "            skip.append(minimo-j-1)            \n",
    "        i += 1\n",
    "    return p/minimo\n",
    "\n",
    "def locateRegion(img):\n",
    "    #gray\n",
    "    gray = get_grayscale(img)\n",
    "    blurred = remove_noise(gray)\n",
    "    dilated = dilate(blurred)\n",
    "    eroded = erode(dilated)\n",
    "    thresh = cv2.threshold(eroded, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "    image_copy = img.copy()\n",
    "    cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    all_areas= []\n",
    "    for cnt in contours:\n",
    "        area= cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)\n",
    "    mask = np.zeros_like(image_copy) # Queremos que nuestra región de interés sea blanca, y si no, negra\n",
    "    cv2.drawContours(mask, sorted_contours, 0, (255,255,255), -1) # Hacemos que la región de interés sea blanca\n",
    "    out = np.zeros_like(image_copy)\n",
    "    out.fill(255)\n",
    "    out[mask == 255] = img[mask == 255] # Extraemos el objeto y lo ponemos sobre nuestra \"máscara\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "Finished in 3.45 second(s)\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:/Users/alons/Desktop/Universidad/Universidad21.22/TFG/Vision/WA'\n",
    "t = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpeg\"):\n",
    "        start = time.perf_counter()\n",
    "        takepicture()\n",
    "        img = cv2.imread(filename, 0)\n",
    "        img = thresholding(img)\n",
    "        cv2.imwrite('prueba.jpeg', img)\n",
    "        img = cv2.imread('prueba.jpeg')\n",
    "        img = locateRegion(img)\n",
    "        img = deskew(img)\n",
    "        cv2.imwrite('prueba.jpeg', img)\n",
    "        text = imagetotext('prueba.jpeg')\n",
    "        end = time.perf_counter()\n",
    "        t.append(round(end-start, 2))\n",
    "print(f'Finished in {round(end-start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('tiemposrpi.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.82 14.13 16.74 15.16 16.04 12.33 16.74 16.74 13.58 13.76 14.74 19.72\n",
      " 14.69 17.07 16.16 23.74 16.63 16.46 19.71 14.79 15.76 19.06 14.53 17.68\n",
      " 16.92 18.22 13.37 20.52 18.57 14.93 13.7  14.42 14.17 12.89 14.28 15.74\n",
      " 17.44 14.93 12.24 16.76 15.85 20.96 19.77 14.96 14.53 13.81 21.   15.61\n",
      " 12.68]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
